{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Set the Azure ML Workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to work with', ws.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to work with azuremlws\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626801453301
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the baseline dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Datastore, Dataset\r\n",
        "\r\n",
        "# Upload the baseline data\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "default_ds.upload_files(files=['./data/heart_failure.csv', './data/heart_failure2.csv'],\r\n",
        "                       target_path='heart-baseline',\r\n",
        "                       overwrite=True, \r\n",
        "                       show_progress=True)\r\n",
        "\r\n",
        "# Create and register the baseline dataset\r\n",
        "print('Registering baseline dataset...')\r\n",
        "baseline_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'heart-baseline/*.csv'))\r\n",
        "baseline_data_set = baseline_data_set.register(workspace=ws, \r\n",
        "                           name='heart-baseline',\r\n",
        "                           description='heart baseline data',\r\n",
        "                           tags = {'format':'CSV'},\r\n",
        "                           create_new_version=True)\r\n",
        "\r\n",
        "print('Baseline dataset registered!')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading an estimated of 2 files\n",
            "Uploading ./data/heart_failure.csv\n",
            "Uploaded ./data/heart_failure.csv, 1 files out of an estimated total of 2\n",
            "Uploading ./data/heart_failure2.csv\n",
            "Uploaded ./data/heart_failure2.csv, 2 files out of an estimated total of 2\n",
            "Uploaded 2 files\n",
            "Registering baseline dataset...\n",
            "Baseline dataset registered!\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626795882421
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate simulated data and regsiter the target dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "\r\n",
        "# Load the smaller of the two data files\r\n",
        "data = pd.read_csv('data/heart_failure2.csv')\r\n",
        "\r\n",
        "# We'll generate data for the past 3 weeks\r\n",
        "weeknos = reversed(range(3))\r\n",
        "\r\n",
        "file_paths = []\r\n",
        "for weekno in weeknos:\r\n",
        "    \r\n",
        "    # Get the date X weeks ago\r\n",
        "    data_date = dt.date.today() - dt.timedelta(weeks=weekno)\r\n",
        "    \r\n",
        "    # Modify data to ceate some drift\r\n",
        "    data['anaemia'] = data['anaemia'] + 1\r\n",
        "    data['age'] = round(data['age'] * 1.2).astype(int)\r\n",
        "    \r\n",
        "    \r\n",
        "    # Save the file with the date encoded in the filename\r\n",
        "    file_path = 'data/heart_{}.csv'.format(data_date.strftime(\"%Y-%m-%d\"))\r\n",
        "    data.to_csv(file_path)\r\n",
        "    file_paths.append(file_path)\r\n",
        "\r\n",
        "# Upload the files\r\n",
        "path_on_datastore = 'heart-target'\r\n",
        "default_ds.upload_files(files=file_paths,\r\n",
        "                       target_path=path_on_datastore,\r\n",
        "                       overwrite=True,\r\n",
        "                       show_progress=True)\r\n",
        "\r\n",
        "# Use the folder partition format to define a dataset with a 'date' timestamp column\r\n",
        "partition_format = path_on_datastore + '/heart_{date:yyyy-MM-dd}.csv'\r\n",
        "target_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, path_on_datastore + '/*.csv'),\r\n",
        "                                                       partition_format=partition_format)\r\n",
        "\r\n",
        "# Register the target dataset\r\n",
        "print('Registering target dataset...')\r\n",
        "target_data_set = target_data_set.with_timestamp_columns('date').register(workspace=ws,\r\n",
        "                                                                          name='heart target',\r\n",
        "                                                                          description='heart target data',\r\n",
        "                                                                          tags = {'format':'CSV'},\r\n",
        "                                                                          create_new_version=True)\r\n",
        "\r\n",
        "print('Target dataset registered!')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating simulated data...\n",
            "Uploading an estimated of 3 files\n",
            "Uploading data/heart_2021-07-06.csv\n",
            "Uploaded data/heart_2021-07-06.csv, 1 files out of an estimated total of 3\n",
            "Uploading data/heart_2021-07-13.csv\n",
            "Uploaded data/heart_2021-07-13.csv, 2 files out of an estimated total of 3\n",
            "Uploading data/heart_2021-07-20.csv\n",
            "Uploaded data/heart_2021-07-20.csv, 3 files out of an estimated total of 3\n",
            "Uploaded 3 files\n",
            "Registering target dataset...\n",
            "Target dataset registered!\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626796098179
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the AML Compute"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = \"AMLAZURECOMPUTE\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    # If it doesn't already exist, create it\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\r\n",
        "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "        training_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating......\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626796392235
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify if azureml-datadrift pacakcge is installed in the environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show azureml-datadrift"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: azureml-datadrift\r\n",
            "Version: 1.31.0\r\n",
            "Summary: Azure Machine Learning datadrift\r\n",
            "Home-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py\r\n",
            "Author: Microsoft Corp\r\n",
            "Author-email: None\r\n",
            "License: https://aka.ms/azureml-sdk-license\r\n",
            "Location: /anaconda/envs/azureml_py36/lib/python3.6/site-packages\r\n",
            "Requires: pandas, msrest, azureml-telemetry, jsonpickle, matplotlib, numpy, pyspark, azureml-dataset-runtime, azureml-pipeline-core, scikit-learn, azureml-core, scipy, lightgbm\r\n",
            "Required-by: \r\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the DataDrift Detector based on the listed features"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.datadrift import DataDriftDetector\r\n",
        "\r\n",
        "# set up feature list\r\n",
        "features = ['anaemia', 'age']\r\n",
        "\r\n",
        "# set up data drift detector\r\n",
        "monitor = DataDriftDetector.create_from_datasets(ws, 'mslearn-heart-drift', baseline_data_set, target_data_set,\r\n",
        "                                                      compute_target=cluster_name, \r\n",
        "                                                      frequency='Week', \r\n",
        "                                                      feature_list=features, \r\n",
        "                                                      drift_threshold=.3, \r\n",
        "                                                      latency=24)\r\n",
        "monitor"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "{'_workspace': Workspace.create(name='azuremlws', subscription_id='1cad424f-916b-47e1-bb04-5e8889f177d8', resource_group='azuremldemo'), '_frequency': 'Week', '_schedule_start': None, '_schedule_id': None, '_interval': 1, '_state': 'Disabled', '_alert_config': None, '_type': 'DatasetBased', '_id': '0dd368e9-c37a-4e62-8072-877118fdbe51', '_model_name': None, '_model_version': 0, '_services': None, '_compute_target_name': 'AMLAZURECOMPUTE', '_drift_threshold': 0.3, '_baseline_dataset_id': '4c61173c-2005-4664-a0d6-a77c37334860', '_target_dataset_id': '8033bd3e-1921-4e69-9b82-6d708e283099', '_feature_list': ['anaemia', 'age'], '_latency': 24, '_name': 'mslearn-heart-drift', '_latest_run_time': None, '_client': <azureml.datadrift._restclient.datadrift_client.DataDriftClient object at 0x7f6a6699bdd8>, '_logger': <_TelemetryLoggerContextAdapter azureml.datadrift._logging._telemetry_logger.azureml.datadrift.datadriftdetector (DEBUG)>}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626796407169
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the backfill option to monitor datadrift back in time"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\r\n",
        "backfill = monitor.backfill(dt.datetime.now() - dt.timedelta(weeks=6), dt.datetime.now())\r\n",
        "RunDetails(backfill).show()\r\n",
        "backfill.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b353f16e78446eda0b5bd035c03f305"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/mslearn-heart-drift-Monitor-Runs_1626796471886?wsid=/subscriptions/1cad424f-916b-47e1-bb04-5e8889f177d8/resourcegroups/azuremldemo/workspaces/azuremlws&tid=1aa51068-11a6-4bd2-8646-1fff31a30ffc\", \"run_id\": \"mslearn-heart-drift-Monitor-Runs_1626796471886\", \"run_properties\": {\"run_id\": \"mslearn-heart-drift-Monitor-Runs_1626796471886\", \"created_utc\": \"2021-07-20T15:54:33.936366Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"74e76c8d-c6ca-490c-98c5-c5c841930c2f\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\", \"azureml.RuntimeType\": \"\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-07-20T16:11:04.182969Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/20_image_build_log.txt\": \"https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=Qmb5%2BQxZZ4kP5mwuNK3H2UazmXZgA0o1nJnjTtWhVzQ%3D&st=2021-07-20T17%3A01%3A04Z&se=2021-07-21T01%3A11%3A04Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt\": \"https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/55_azureml-execution-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt?sv=2019-02-02&sr=b&sig=7%2B%2FSVdRS8NijqUmQ3X1uWWw4TdkD37FUtdM7i5U79lg%3D&st=2021-07-20T17%3A01%3A04Z&se=2021-07-21T01%3A11%3A04Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt\": \"https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/65_job_prep-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt?sv=2019-02-02&sr=b&sig=nB0ont7wabaM98ou8hCZd0YIWzmL7tmfMngIu8CHuAI%3D&st=2021-07-20T17%3A01%3A04Z&se=2021-07-21T01%3A11%3A04Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=HIYLXPJTLJFf%2BVxdzp%2BBYhDlwD6U1fqt%2F3XVCGl9rZQ%3D&st=2021-07-20T17%3A01%3A04Z&se=2021-07-21T01%3A11%3A04Z&sp=r\", \"azureml-logs/75_job_post-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt\": \"https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/75_job_post-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt?sv=2019-02-02&sr=b&sig=ctffuP55E8wRFtZdXzw%2BG8h9mRQHx5onNGyEPAbGENQ%3D&st=2021-07-20T17%3A01%3A04Z&se=2021-07-21T01%3A11%3A04Z&sp=r\", \"azureml-logs/process_info.json\": \"https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=AUUUJwGZzjDAQy2wB5mSwNpkTQ3rlbt%2FKOOGfZ%2BP6WY%3D&st=2021-07-20T17%3A01%3A04Z&se=2021-07-21T01%3A11%3A04Z&sp=r\", \"azureml-logs/process_status.json\": \"https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=dWEsmdCffc%2BXbxVKYFWFC00qbwtTsLX0QOSuh1vEf%2FE%3D&st=2021-07-20T17%3A01%3A04Z&se=2021-07-21T01%3A11%3A04Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\"], [\"azureml-logs/20_image_build_log.txt\"], [\"azureml-logs/55_azureml-execution-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt\"]], \"run_duration\": \"0:16:30\", \"run_number\": \"1\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"start_date\", \"run_id\": \"mslearn-heart-drift-Monitor-Runs_1626796471886\", \"categories\": [0], \"series\": [{\"data\": [\"2021-06-06\"]}]}, {\"name\": \"end_date\", \"run_id\": \"mslearn-heart-drift-Monitor-Runs_1626796471886\", \"categories\": [0], \"series\": [{\"data\": [\"2021-07-25\"]}]}, {\"name\": \"frequency\", \"run_id\": \"mslearn-heart-drift-Monitor-Runs_1626796471886\", \"categories\": [0], \"series\": [{\"data\": [\"Week\"]}]}, {\"name\": \"Datadrift percentage\", \"run_id\": \"mslearn-heart-drift-Monitor-Runs_1626796471886\", \"categories\": [0], \"series\": [{\"data\": [{\"days_from_start\": [28, 35, 42], \"drift_percentage\": [75.51430421160069, 100.0, 100.0]}]}]}], \"run_logs\": \"[2021-07-20T16:10:35.945269] Entering job release\\r\\n[2021-07-20T16:10:36.899404] Starting job release\\r\\n[2021-07-20T16:10:36.900221] Logging experiment finalizing status in history service.\\r\\nStarting the daemon thread to refresh tokens in background for process with pid = 789\\r\\n[2021-07-20T16:10:36.900728] job release stage : upload_datastore starting...\\r\\n[2021-07-20T16:10:36.909524] job release stage : start importing azureml.history._tracking in run_history_release.\\r\\n[2021-07-20T16:10:36.909563] job release stage : execute_job_release starting...\\r\\n[2021-07-20T16:10:36.909854] Entering context manager injector.\\r\\n[2021-07-20T16:10:36.910426] job release stage : copy_batchai_cached_logs starting...\\r\\n[2021-07-20T16:10:36.910474] job release stage : copy_batchai_cached_logs completed...\\r\\n[2021-07-20T16:10:36.913644] job release stage : upload_datastore completed...\\r\\n[2021-07-20T16:10:37.020233] job release stage : send_run_telemetry starting...\\r\\n[2021-07-20T16:10:37.058973] get vm size and vm region successfully.\\r\\n[2021-07-20T16:10:37.070776] get compute meta data successfully.\\r\\n[2021-07-20T16:10:37.217649] job release stage : execute_job_release completed...\\r\\n[2021-07-20T16:10:37.392599] post artifact meta request successfully.\\r\\n[2021-07-20T16:10:37.456221] upload compute record artifact successfully.\\r\\n[2021-07-20T16:10:37.456302] job release stage : send_run_telemetry completed...\\r\\n[2021-07-20T16:10:37.456646] Job release is complete\\r\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.31.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "{'runId': 'mslearn-heart-drift-Monitor-Runs_1626796471886',\n 'target': 'AMLAZURECOMPUTE',\n 'status': 'Finalizing',\n 'startTimeUtc': '2021-07-20T16:07:24.618575Z',\n 'warnings': [{'source': 'datadrift',\n   'message': 'target dataset id:8033bd3e-1921-4e69-9b82-6d708e283099 do not contain sufficient amount of data after timestamp filteringMinimum needed: 50 rows.Skipping calculation for time slice 2021-06-06 00:00:00 to 2021-06-13 00:00:00.'},\n  {'source': 'datadrift',\n   'message': 'target dataset id:8033bd3e-1921-4e69-9b82-6d708e283099 do not contain sufficient amount of data after timestamp filteringMinimum needed: 50 rows.Skipping calculation for time slice 2021-06-13 00:00:00 to 2021-06-20 00:00:00.'},\n  {'source': 'datadrift',\n   'message': 'target dataset id:8033bd3e-1921-4e69-9b82-6d708e283099 do not contain sufficient amount of data after timestamp filteringMinimum needed: 50 rows.Skipping calculation for time slice 2021-06-20 00:00:00 to 2021-06-27 00:00:00.'},\n  {'source': 'datadrift',\n   'message': 'target dataset id:8033bd3e-1921-4e69-9b82-6d708e283099 do not contain sufficient amount of data after timestamp filteringMinimum needed: 50 rows.Skipping calculation for time slice 2021-06-27 00:00:00 to 2021-07-04 00:00:00.'}],\n 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n  'ContentSnapshotId': '74e76c8d-c6ca-490c-98c5-c5c841930c2f',\n  'ProcessInfoFile': 'azureml-logs/process_info.json',\n  'ProcessStatusFile': 'azureml-logs/process_status.json',\n  'azureml.RuntimeType': ''},\n 'inputDatasets': [{'dataset': {'id': '4c61173c-2005-4664-a0d6-a77c37334860'}, 'consumptionDetails': {'type': 'Reference'}}, {'dataset': {'id': '8033bd3e-1921-4e69-9b82-6d708e283099'}, 'consumptionDetails': {'type': 'Reference'}}],\n 'outputDatasets': [],\n 'runDefinition': {'script': '_generate_script_datasets.py',\n  'useAbsolutePath': False,\n  'arguments': ['--baseline_dataset_id',\n   '4c61173c-2005-4664-a0d6-a77c37334860',\n   '--target_dataset_id',\n   '8033bd3e-1921-4e69-9b82-6d708e283099',\n   '--workspace_name',\n   'azuremlws',\n   '--workspace_location',\n   'canadacentral',\n   '--instrumentation_key',\n   '5c1d0cf8-de3e-43c1-87a8-ff7bd1c2ed97',\n   '--ai_endpoint',\n   'https://dc.applicationinsights.azure.com/v2/track',\n   '--subscription_id',\n   '1cad424f-916b-47e1-bb04-5e8889f177d8',\n   '--enable_metric_logger',\n   'true',\n   '--run_type',\n   'BackFill',\n   '--drift_threshold',\n   '0',\n   '--datadrift_id',\n   '0dd368e9-c37a-4e62-8072-877118fdbe51',\n   '--datadrift_run_id',\n   'b429d84c-8cab-442c-afc8-c01505cde128',\n   '--datadrift_name',\n   'mslearn-heart-drift',\n   '--frequency',\n   'Week',\n   '--datadrift_configuration_type',\n   'DatasetBased',\n   '--start_date',\n   '2021-06-06',\n   '--end_date',\n   '2021-07-25',\n   '--features_whitelist',\n   'anaemia',\n   'age'],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'AMLAZURECOMPUTE',\n  'dataReferences': {},\n  'data': {},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': None,\n  'nodeCount': 1,\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'Experiment mslearn-heart-drift-Monitor-Runs Environment',\n   'version': 'Autosave_2021-07-20T15:54:33Z_e492d20f',\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'dependencies': ['python=3.6.2',\n      'scikit-learn',\n      'scipy>=1.0.0',\n      'numpy',\n      'lightgbm<=3.1.0',\n      'pandas',\n      'pyarrow>=0.11.0',\n      'jsonpickle',\n      'psutil',\n      {'pip': ['azureml-defaults==1.30.0', 'azureml-datadrift==1.30.0']}],\n     'name': 'azureml_8eb0c3e77e1fd9098452b983543955bc'},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None,\n     'username': None,\n     'password': None}},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': None,\n   'enableMLflowTracking': False},\n  'spark': {'configuration': {}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': 1},\n  'aiSuperComputer': {'instanceType': None,\n   'imageVersion': None,\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'enableAzmlInt': True,\n   'priority': None,\n   'slaTier': None},\n  'tensorflow': {'workerCount': 0, 'parameterServerCount': 0},\n  'mpi': {'processCountPerNode': 0},\n  'pyTorch': {'communicationBackend': None, 'processCount': None},\n  'hdi': {'yarnDeployMode': 'None'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': True,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=J4Zk4ByolE%2F2JLOWAhBqAYvDvVPBBPDff3p%2BAK8Wz7c%3D&st=2021-07-20T16%3A00%3A50Z&se=2021-07-21T00%3A10%3A50Z&sp=r',\n  'azureml-logs/55_azureml-execution-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt': 'https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/55_azureml-execution-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt?sv=2019-02-02&sr=b&sig=6gPVJbMJQcMVEDYsVcOpwdcCUJC4idexrbBNNDUTlr4%3D&st=2021-07-20T16%3A00%3A50Z&se=2021-07-21T00%3A10%3A50Z&sp=r',\n  'azureml-logs/65_job_prep-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt': 'https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/65_job_prep-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt?sv=2019-02-02&sr=b&sig=c3p%2FK5UlqAxQi1ERU7rJ60uTrN6yjAJTBeqqeLwUQW8%3D&st=2021-07-20T16%3A00%3A50Z&se=2021-07-21T00%3A10%3A50Z&sp=r',\n  'azureml-logs/70_driver_log.txt': 'https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=UmsoLBK1w8whlxnNpJ7AFJwF%2BHQlycJiYGvj5n0Ejz0%3D&st=2021-07-20T16%3A00%3A50Z&se=2021-07-21T00%3A10%3A50Z&sp=r',\n  'azureml-logs/75_job_post-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt': 'https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/75_job_post-tvmps_6fc296d2c3096764f72409a3f4a54901ee3230da85e92413b1061bb4eb1944b9_d.txt?sv=2019-02-02&sr=b&sig=ul7EZQoWzIdNhdvnFjsGc3FB0sYF8wDZyrltBrxoNRI%3D&st=2021-07-20T16%3A00%3A50Z&se=2021-07-21T00%3A10%3A50Z&sp=r',\n  'azureml-logs/process_info.json': 'https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=wZeTp7RhAt%2FqpAfBN2VDpullxccj3B76uRAx5DhfYC4%3D&st=2021-07-20T16%3A00%3A50Z&se=2021-07-21T00%3A10%3A50Z&sp=r',\n  'azureml-logs/process_status.json': 'https://azuremlws8775131292.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-heart-drift-Monitor-Runs_1626796471886/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=LHxR6Asrap22Xwbycba5Z443hZU%2Bi2lQPKTCWfssUDA%3D&st=2021-07-20T16%3A00%3A50Z&se=2021-07-21T00%3A10%3A50Z&sp=r'},\n 'submittedBy': 'Kishore Jayabalan'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626797456591
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the data drift metrics"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drift_metrics = backfill.get_metrics()\r\n",
        "for metric in drift_metrics:\r\n",
        "    print(metric, drift_metrics[metric])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_date 2021-06-06\n",
            "end_date 2021-07-25\n",
            "frequency Week\n",
            "Datadrift percentage {'days_from_start': [28, 35, 42], 'drift_percentage': [75.51430421160069, 100.0, 100.0]}\n"
          ]
        }
      ],
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626799337207
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}